---
linktitle: 第 3 章：自动分析的局限性
summary: 第 3 章：自动分析的局限性
weight: 4
title: 第 3 章：自动分析的局限性
date: '2022-02-05T00:00:00+08:00'
type: book
---

自动化开始听起来很神奇，但我们要面对现实：计算机分析不能每天告诉你系统有什么问题或为你修复它。它只能为你节省时间。

至此，我想停止夸赞，我必须承认自动化的一些局限性。我这样做是因为围绕结合人工智能和可观测性会有相当多的炒作。这种炒作导致了惊人的论断，大意是："人工智能异常检测和根源分析可以完全诊断问题！" 和 "人工智能操作将完全管理你的系统！"

## 谨防炒作

为了摆脱此类炒作，我想明确的是，这类梦幻般的营销主张**并不是**我所宣称的现代可观测性将提供的。事实上，我预测许多与人工智能问题解决有关的主张大多是夸大其词。

为什么人工智能不能解决我们的问题？一般来说，机器无法识别软件中的 "问题"，因为定义什么是 "问题" 需要一种主观的分析方式。而我们所讨论的那种现实世界的人工智能不能以任何程度的准确性进行主观决策。机器将始终缺乏足够的背景。

例如，我们说该版本降低了性能，这里面也隐含了一个期望，就是这个版本包含了每个用户都期望的新功能。对于这个版本，性能退步是一个特征，而不是一个错误。

虽然它们可能看起来像类似的活动，但在**确定相关关系**和**确定根本原因**之间存在着巨大的鸿沟。当你有正确的数据结构时，相关性是一种**客观的分析** —— 你只需要计算数字。哪些相关关系是相关的，并表明真正问题的来源，总是需要**主观的分析**，对数据的解释。所有这些相关关系意味着什么？正如杰弗里・李波斯基（Jeffrey Lebowski）所说："嗯，你知道，这只是你的观点，伙计。"

## 神奇的 AIOps

在调查一个系统时，有两种类型的分析起作用：

- 客观的分析，基于事实的、可衡量的、可观测的。
- 主观分析，基于解释、观点和判断的。

这种二分法 —— 客观与主观，与可计算性理论中一个重要的问题有关，即 **[停机问题（halting problem）](https://en.wikipedia.org/wiki/Halting_problem)**。停机问题的定义是，在给定任意计算机程序及其输入的描述的情况下，是否可以编写一个计算机程序来确定任意程序是否会结束运行或永远继续运行。简而言之，在 1936 年，艾伦・图灵（Alan Turning）证明了解决停机问题的一般算法是不存在的，这个证明的延伸可以应用于计算机软件中许多形式的识别 "问题"。

阿兰・图灵的意思是，我们没有办法拥有神奇的 AIOps（IT 运维的人工智能）。寻找那些承诺将繁琐的客观分析自动化的工具 —— 计算数字是机器的强项！但要小心那些声称能找到问题根源并自动修复的工具。它们很可能会让你失望。

这就是为什么我们可以确定相关关系，但不能确定因果关系：想象一下，有一台机器可以确定任意计算机程序中的问题行为是什么，并确定该行为的根本原因。如果我们真的造出了这样一台机器，那就是开香槟的时候了，因为这意味着我们终于解决了停机问题！但是，目前还没有迹象表明，机器可以解决这个问题。然而，没有迹象表明机器学习已经超越了艾伦・图灵的统一计算模型；你可以相信，这不会发生。

做出正确的决定和修复的工作还是要靠你自己。

## 时间是最宝贵的资源

然而，我们不需要神奇的 AIOps 来看到我们工作流程的巨大改善。识别相关性，同时获取相关信息，以便你能有效地浏览这些信息，这是计算机**绝对可以**做到的事情！这将为你节省时间。大量的时间。这么多的时间，它将从根本上改变你调查系统的方式。

减少浪费的时间是实践现代可观测性的核心。即使是在简单的系统中，通过分析数字来识别相关性也是很困难的，而在大规模的系统中，这几乎是不可能的。通过将认知负担转移到机器上，运维人员能够有效地管理那些已经超出人类头脑所能容纳的系统。

但是，我们分析遥测方式的这种转变并不是可观测性世界中即将发生的唯一重大变化。我们需要的大部分遥测数据来自于我们没有编写的软件：我们所依赖的开源库、数据库和管理服务。这些系统在传统上一直在为产生遥测数据而奋斗。我们可以获得哪些数据，以及这些数据来自哪里，也将发生根本性的变化。